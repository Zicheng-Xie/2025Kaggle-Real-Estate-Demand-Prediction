{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3ae815",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:32.810527Z",
     "iopub.status.busy": "2025-10-10T04:04:32.810190Z",
     "iopub.status.idle": "2025-10-10T04:04:34.963234Z",
     "shell.execute_reply": "2025-10-10T04:04:34.961911Z"
    },
    "papermill": {
     "duration": 2.1664,
     "end_time": "2025-10-10T04:04:34.964993",
     "exception": false,
     "start_time": "2025-10-10T04:04:32.798593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/china-real-estate-demand-prediction/sample_submission.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/test.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/city_search_index.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/land_transactions_nearby_sectors.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/new_house_transactions_nearby_sectors.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/city_indexes.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/pre_owned_house_transactions.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/new_house_transactions.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/land_transactions.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/sector_POI.csv\n",
      "/kaggle/input/china-real-estate-demand-prediction/train/pre_owned_house_transactions_nearby_sectors.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "566c0283",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:34.981314Z",
     "iopub.status.busy": "2025-10-10T04:04:34.980963Z",
     "iopub.status.idle": "2025-10-10T04:04:38.595743Z",
     "shell.execute_reply": "2025-10-10T04:04:38.594880Z"
    },
    "papermill": {
     "duration": 3.624686,
     "end_time": "2025-10-10T04:04:38.597374",
     "exception": false,
     "start_time": "2025-10-10T04:04:34.972688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Real Estate Demand — Metric-aware, Leakage-safe Ensemble\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1354f9b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.614273Z",
     "iopub.status.busy": "2025-10-10T04:04:38.613696Z",
     "iopub.status.idle": "2025-10-10T04:04:38.618910Z",
     "shell.execute_reply": "2025-10-10T04:04:38.617880Z"
    },
    "papermill": {
     "duration": 0.015321,
     "end_time": "2025-10-10T04:04:38.620319",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.604998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- Paths ----------\n",
    "PTH = Path(\"/kaggle/input/china-real-estate-demand-prediction\")\n",
    "OUT = Path(\"/kaggle/working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7c38104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.640530Z",
     "iopub.status.busy": "2025-10-10T04:04:38.640191Z",
     "iopub.status.idle": "2025-10-10T04:04:38.645377Z",
     "shell.execute_reply": "2025-10-10T04:04:38.644071Z"
    },
    "papermill": {
     "duration": 0.016789,
     "end_time": "2025-10-10T04:04:38.647393",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.630604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- Helpers ----------\n",
    "MONTH2NUM = dict(Jan=1, Feb=2, Mar=3, Apr=4, May=5, Jun=6,\n",
    "                 Jul=7, Aug=8, Sep=9, Oct=10, Nov=11, Dec=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5907b1d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.665775Z",
     "iopub.status.busy": "2025-10-10T04:04:38.665462Z",
     "iopub.status.idle": "2025-10-10T04:04:38.671686Z",
     "shell.execute_reply": "2025-10-10T04:04:38.670349Z"
    },
    "papermill": {
     "duration": 0.018321,
     "end_time": "2025-10-10T04:04:38.673559",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.655238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def parse_time(df, month_col=\"month\"):\n",
    "    # df['month'] like '2020-Jan' or '2024 Aug' in test id\n",
    "    if month_col == \"month\":\n",
    "        yr = df[month_col].str.slice(0, 4).astype(int)\n",
    "        mo_txt = df[month_col].str.slice(5)\n",
    "        mo = mo_txt.map(MONTH2NUM).astype(int)\n",
    "    else:\n",
    "        # for test: month_text like '2024 Aug'\n",
    "        yr = df[month_col].str.slice(0, 4).astype(int)\n",
    "        mo_txt = df[month_col].str.slice(5)\n",
    "        mo = mo_txt.map(MONTH2NUM).astype(int)\n",
    "    df[\"year\"] = yr\n",
    "    df[\"month_num\"] = mo\n",
    "    df[\"time\"] = (df[\"year\"] - 2019) * 12 + df[\"month_num\"] - 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ed3b7fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.690948Z",
     "iopub.status.busy": "2025-10-10T04:04:38.690531Z",
     "iopub.status.idle": "2025-10-10T04:04:38.696446Z",
     "shell.execute_reply": "2025-10-10T04:04:38.695595Z"
    },
    "papermill": {
     "duration": 0.016248,
     "end_time": "2025-10-10T04:04:38.697963",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.681715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_test_id(test):\n",
    "    parts = test[\"id\"].str.split(\"_\", expand=True)\n",
    "    test[\"month_text\"] = parts[0]\n",
    "    test[\"sector\"] = parts[1]\n",
    "    test[\"sector_id\"] = test[\"sector\"].str.replace(\"sector \", \"\", regex=False).astype(int)\n",
    "    test = parse_time(test.rename(columns={\"month_text\":\"month_parsed\"}), \"month_parsed\")\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bfedb44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.715179Z",
     "iopub.status.busy": "2025-10-10T04:04:38.714804Z",
     "iopub.status.idle": "2025-10-10T04:04:38.720558Z",
     "shell.execute_reply": "2025-10-10T04:04:38.718832Z"
    },
    "papermill": {
     "duration": 0.016378,
     "end_time": "2025-10-10T04:04:38.722308",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.705930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lunar New Year (LNY) month indicator for 2019–2024 (simple, robust flag)\n",
    "# source: public calendars; encoded explicitly to avoid internet calls.\n",
    "LNY_MONTH_BY_YEAR = {2019:2, 2020:1, 2021:2, 2022:2, 2023:1, 2024:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5743927f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.741583Z",
     "iopub.status.busy": "2025-10-10T04:04:38.741057Z",
     "iopub.status.idle": "2025-10-10T04:04:38.747755Z",
     "shell.execute_reply": "2025-10-10T04:04:38.746341Z"
    },
    "papermill": {
     "duration": 0.019516,
     "end_time": "2025-10-10T04:04:38.749613",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.730097",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_calendar_feats(df):\n",
    "    m = df[\"month_num\"]\n",
    "    df[\"sin12\"] = np.sin(2*np.pi*(m-1)/12)\n",
    "    df[\"cos12\"] = np.cos(2*np.pi*(m-1)/12)\n",
    "    df[\"sin6\"]  = np.sin(2*np.pi*(m-1)/6)\n",
    "    df[\"cos6\"]  = np.cos(2*np.pi*(m-1)/6)\n",
    "    df[\"qtr\"]   = ((m-1)//3 + 1).astype(int)\n",
    "\n",
    "    # LNY month flag and the month before LNY\n",
    "    df[\"lny_month\"] = df[\"year\"].map(LNY_MONTH_BY_YEAR).fillna(0).astype(int)\n",
    "    df[\"is_lny\"]    = (df[\"month_num\"] == df[\"lny_month\"]).astype(int)\n",
    "    df[\"is_pre_lny\"]= ((df[\"month_num\"] % 12) == ((df[\"lny_month\"]-1-1) % 12)+1).astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5016898a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.766665Z",
     "iopub.status.busy": "2025-10-10T04:04:38.766250Z",
     "iopub.status.idle": "2025-10-10T04:04:38.773748Z",
     "shell.execute_reply": "2025-10-10T04:04:38.772629Z"
    },
    "papermill": {
     "duration": 0.017773,
     "end_time": "2025-10-10T04:04:38.775127",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.757354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ewgm(x, n_lags=6, alpha=0.6):\n",
    "    \"\"\"Exponentially Weighted Geometric Mean on tail values > 0.\"\"\"\n",
    "    vals = x[-n_lags:]\n",
    "    if len(vals)==0 or (vals>0).sum()==0: \n",
    "        return 0.0\n",
    "    w = np.array([alpha**(n_lags-1-i) for i in range(n_lags)], float)\n",
    "    w = w / w.sum()\n",
    "    pos = vals>0\n",
    "    if pos.sum()==0: \n",
    "        return 0.0\n",
    "    logv = np.log(np.where(vals[pos]<=0, 1e-12, vals[pos]))\n",
    "    ww = w[pos] / w[pos].sum()\n",
    "    return float(np.exp((ww*logv).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "257c4743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.792792Z",
     "iopub.status.busy": "2025-10-10T04:04:38.792385Z",
     "iopub.status.idle": "2025-10-10T04:04:38.799289Z",
     "shell.execute_reply": "2025-10-10T04:04:38.797429Z"
    },
    "papermill": {
     "duration": 0.018475,
     "end_time": "2025-10-10T04:04:38.801275",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.782800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def december_multipliers(wide_amount, clip=(0.85, 1.4)):\n",
    "    idx = wide_amount.index\n",
    "    is_dec = (idx % 12)==11\n",
    "    dec_mean = wide_amount[is_dec].mean(0)\n",
    "    other_mean = wide_amount[~is_dec].mean(0)\n",
    "    overall = dec_mean.mean()/(other_mean.mean()+1e-12)\n",
    "    mult = dec_mean/(other_mean+1e-12)\n",
    "    mult = mult.fillna(overall).replace([np.inf,-np.inf], 1.0)\n",
    "    return mult.clip(*clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ab68d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.818653Z",
     "iopub.status.busy": "2025-10-10T04:04:38.818334Z",
     "iopub.status.idle": "2025-10-10T04:04:38.824895Z",
     "shell.execute_reply": "2025-10-10T04:04:38.822867Z"
    },
    "papermill": {
     "duration": 0.016955,
     "end_time": "2025-10-10T04:04:38.826643",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.809688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_score(y_true, y_pred, eps=1e-12):\n",
    "    y_true = np.asarray(y_true, float)\n",
    "    y_pred = np.maximum(np.asarray(y_pred, float), 0.0)\n",
    "    ape = np.abs(y_true - y_pred) / np.maximum(y_true, eps)\n",
    "    if (ape>1).mean() > 0.30:\n",
    "        return 0.0\n",
    "    good = ape<=1\n",
    "    if not np.any(good):\n",
    "        return 0.0\n",
    "    mape = ape[good].mean()\n",
    "    fraction = good.mean()\n",
    "    return max(0.0, 1.0 - mape/(fraction+eps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d66b26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:38.843222Z",
     "iopub.status.busy": "2025-10-10T04:04:38.842970Z",
     "iopub.status.idle": "2025-10-10T04:04:38.991654Z",
     "shell.execute_reply": "2025-10-10T04:04:38.990064Z"
    },
    "papermill": {
     "duration": 0.159068,
     "end_time": "2025-10-10T04:04:38.993556",
     "exception": false,
     "start_time": "2025-10-10T04:04:38.834488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- Load ----------\n",
    "nht = pd.read_csv(PTH/\"train/new_house_transactions.csv\")\n",
    "pht = pd.read_csv(PTH/\"train/pre_owned_house_transactions.csv\")\n",
    "lt  = pd.read_csv(PTH/\"train/land_transactions.csv\")\n",
    "nht_ns = pd.read_csv(PTH/\"train/new_house_transactions_nearby_sectors.csv\")\n",
    "pht_ns = pd.read_csv(PTH/\"train/pre_owned_house_transactions_nearby_sectors.csv\")\n",
    "lt_ns  = pd.read_csv(PTH/\"train/land_transactions_nearby_sectors.csv\")\n",
    "poi = pd.read_csv(PTH/\"train/sector_POI.csv\")\n",
    "city_idx = pd.read_csv(PTH/\"train/city_indexes.csv\")\n",
    "test = pd.read_csv(PTH/\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adc6411e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.010660Z",
     "iopub.status.busy": "2025-10-10T04:04:39.010379Z",
     "iopub.status.idle": "2025-10-10T04:04:39.062682Z",
     "shell.execute_reply": "2025-10-10T04:04:39.061070Z"
    },
    "papermill": {
     "duration": 0.062574,
     "end_time": "2025-10-10T04:04:39.064557",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.001983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- Parse basics ----------\n",
    "for df in [nht, pht, lt, nht_ns, pht_ns, lt_ns]:\n",
    "    df[\"sector_id\"] = df[\"sector\"].str.replace(\"sector \", \"\", regex=False).astype(int)\n",
    "    parse_time(df)\n",
    "\n",
    "parse_time(poi.assign(month=\"2019-Jan\"))  # inject year for join-safety\n",
    "poi[\"sector_id\"] = poi[\"sector\"].str.replace(\"sector \", \"\", regex=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a8cdcc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.083130Z",
     "iopub.status.busy": "2025-10-10T04:04:39.082855Z",
     "iopub.status.idle": "2025-10-10T04:04:39.088966Z",
     "shell.execute_reply": "2025-10-10T04:04:39.087485Z"
    },
    "papermill": {
     "duration": 0.017219,
     "end_time": "2025-10-10T04:04:39.090489",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.073270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# join city indexes by year (no .head(6) truncation)\n",
    "city_idx.rename(columns={\"city_indicator_data_year\":\"year\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14b2ca04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.107437Z",
     "iopub.status.busy": "2025-10-10T04:04:39.107186Z",
     "iopub.status.idle": "2025-10-10T04:04:39.121851Z",
     "shell.execute_reply": "2025-10-10T04:04:39.120581Z"
    },
    "papermill": {
     "duration": 0.025055,
     "end_time": "2025-10-10T04:04:39.123413",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.098358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- Build base panel ----------\n",
    "# one row per (sector_id, time)\n",
    "times = nht[\"time\"].unique()\n",
    "sectors = np.arange(1, 97)\n",
    "base = (pd.MultiIndex.from_product([times, sectors], names=[\"time\",\"sector_id\"])\n",
    "        .to_frame(index=False)\n",
    "        .sort_values([\"sector_id\",\"time\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4444e9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.139280Z",
     "iopub.status.busy": "2025-10-10T04:04:39.139050Z",
     "iopub.status.idle": "2025-10-10T04:04:39.183422Z",
     "shell.execute_reply": "2025-10-10T04:04:39.182205Z"
    },
    "papermill": {
     "duration": 0.05421,
     "end_time": "2025-10-10T04:04:39.185085",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.130875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>sector_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month_num</th>\n",
       "      <th>sin12</th>\n",
       "      <th>cos12</th>\n",
       "      <th>sin6</th>\n",
       "      <th>cos6</th>\n",
       "      <th>qtr</th>\n",
       "      <th>lny_month</th>\n",
       "      <th>is_lny</th>\n",
       "      <th>is_pre_lny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>62</td>\n",
       "      <td>96</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6143</th>\n",
       "      <td>63</td>\n",
       "      <td>96</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.123234e-17</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6239</th>\n",
       "      <td>64</td>\n",
       "      <td>96</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6335</th>\n",
       "      <td>65</td>\n",
       "      <td>96</td>\n",
       "      <td>2024</td>\n",
       "      <td>6</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>66</td>\n",
       "      <td>96</td>\n",
       "      <td>2024</td>\n",
       "      <td>7</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6432 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      time  sector_id  year  month_num         sin12         cos12  \\\n",
       "0        0          1  2019          1  0.000000e+00  1.000000e+00   \n",
       "96       1          1  2019          2  5.000000e-01  8.660254e-01   \n",
       "192      2          1  2019          3  8.660254e-01  5.000000e-01   \n",
       "288      3          1  2019          4  1.000000e+00  6.123234e-17   \n",
       "384      4          1  2019          5  8.660254e-01 -5.000000e-01   \n",
       "...    ...        ...   ...        ...           ...           ...   \n",
       "6047    62         96  2024          3  8.660254e-01  5.000000e-01   \n",
       "6143    63         96  2024          4  1.000000e+00  6.123234e-17   \n",
       "6239    64         96  2024          5  8.660254e-01 -5.000000e-01   \n",
       "6335    65         96  2024          6  5.000000e-01 -8.660254e-01   \n",
       "6431    66         96  2024          7  1.224647e-16 -1.000000e+00   \n",
       "\n",
       "              sin6  cos6  qtr  lny_month  is_lny  is_pre_lny  \n",
       "0     0.000000e+00   1.0    1          2       0           1  \n",
       "96    8.660254e-01   0.5    1          2       1           0  \n",
       "192   8.660254e-01  -0.5    1          2       0           0  \n",
       "288   1.224647e-16  -1.0    2          2       0           0  \n",
       "384  -8.660254e-01  -0.5    2          2       0           0  \n",
       "...            ...   ...  ...        ...     ...         ...  \n",
       "6047  8.660254e-01  -0.5    1          2       0           0  \n",
       "6143  1.224647e-16  -1.0    2          2       0           0  \n",
       "6239 -8.660254e-01  -0.5    2          2       0           0  \n",
       "6335 -8.660254e-01   0.5    2          2       0           0  \n",
       "6431 -2.449294e-16   1.0    3          2       0           0  \n",
       "\n",
       "[6432 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attach month/year & season features\n",
    "base[\"year\"] = 2019 + (base[\"time\"]//12)\n",
    "base[\"month_num\"] = (base[\"time\"]%12) + 1\n",
    "add_calendar_feats(base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ade9b26f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.202057Z",
     "iopub.status.busy": "2025-10-10T04:04:39.201813Z",
     "iopub.status.idle": "2025-10-10T04:04:39.207428Z",
     "shell.execute_reply": "2025-10-10T04:04:39.205881Z"
    },
    "papermill": {
     "duration": 0.015713,
     "end_time": "2025-10-10T04:04:39.208794",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.193081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attach targets and raw features for current month (no future joins)\n",
    "def safe_merge(df, cols, suffix):\n",
    "    keep = [\"time\",\"sector_id\"] + cols\n",
    "    out = base.merge(df[keep], on=[\"time\",\"sector_id\"], how=\"left\", suffixes=(\"\",\"\"))\n",
    "    out.rename(columns={c: f\"{c}{suffix}\" for c in cols}, inplace=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bcffdf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.226368Z",
     "iopub.status.busy": "2025-10-10T04:04:39.225154Z",
     "iopub.status.idle": "2025-10-10T04:04:39.231304Z",
     "shell.execute_reply": "2025-10-10T04:04:39.230553Z"
    },
    "papermill": {
     "duration": 0.016289,
     "end_time": "2025-10-10T04:04:39.232685",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.216396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------- 从这里替换：safe_merge + 各数据表 merge ----------\n",
    "\n",
    "# 需要排除的列（已经在 base 里，或不是我们想拼接的特征）\n",
    "EXCLUDE = [\"time\", \"sector_id\", \"sector\", \"month\", \"year\", \"month_num\"]\n",
    "\n",
    "def safe_merge(df, cols, suffix):\n",
    "    \"\"\"\n",
    "    右表先把要保留的特征列重命名为带后缀的名字，然后再和 base 按键合并，避免列名冲突。\n",
    "    \"\"\"\n",
    "    right = df[[\"time\", \"sector_id\"] + cols].copy()\n",
    "    right.rename(columns={c: f\"{c}{suffix}\" for c in cols}, inplace=True)\n",
    "    out = base.merge(right, on=[\"time\", \"sector_id\"], how=\"left\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4facb7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.250033Z",
     "iopub.status.busy": "2025-10-10T04:04:39.249675Z",
     "iopub.status.idle": "2025-10-10T04:04:39.299118Z",
     "shell.execute_reply": "2025-10-10T04:04:39.297723Z"
    },
    "papermill": {
     "duration": 0.060157,
     "end_time": "2025-10-10T04:04:39.300708",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.240551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 先合 new house（本月的真实值，用来构造 y 的未来月标签）\n",
    "base = safe_merge(nht, [\"amount_new_house_transactions\"], \"_nht\")\n",
    "\n",
    "# 注意：下面各表的 cols 都排除了 EXCLUDE，避免 year / month_num 等冲突\n",
    "cols_nhtns = nht_ns.columns.difference(EXCLUDE).tolist()\n",
    "base = safe_merge(nht_ns, cols_nhtns, \"_nhtns\")\n",
    "\n",
    "cols_pht = pht.columns.difference(EXCLUDE).tolist()\n",
    "base = safe_merge(pht, cols_pht, \"_pht\")\n",
    "\n",
    "cols_phtns = pht_ns.columns.difference(EXCLUDE).tolist()\n",
    "base = safe_merge(pht_ns, cols_phtns, \"_phtns\")\n",
    "\n",
    "cols_lt = lt.columns.difference(EXCLUDE).tolist()\n",
    "base = safe_merge(lt, cols_lt, \"_lt\")\n",
    "\n",
    "cols_ltns = lt_ns.columns.difference(EXCLUDE).tolist()\n",
    "base = safe_merge(lt_ns, cols_ltns, \"_ltns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95774507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.317292Z",
     "iopub.status.busy": "2025-10-10T04:04:39.317041Z",
     "iopub.status.idle": "2025-10-10T04:04:39.397047Z",
     "shell.execute_reply": "2025-10-10T04:04:39.395086Z"
    },
    "papermill": {
     "duration": 0.090798,
     "end_time": "2025-10-10T04:04:39.399138",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.308340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# POI 只按 sector_id 合并（没有时间维度），不会冲突\n",
    "base = base.merge(poi.drop(columns=[\"sector\",\"month\"], errors=\"ignore\"), on=\"sector_id\", how=\"left\")\n",
    "\n",
    "# 城市指数按 year 合并（base 已自带 year）\n",
    "base = base.merge(city_idx, on=\"year\", how=\"left\")\n",
    "\n",
    "# ---------- 下面与先前版本保持一致：排序、构造标签与特征 ----------\n",
    "\n",
    "base = base.sort_values([\"sector_id\",\"time\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99d66205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.418226Z",
     "iopub.status.busy": "2025-10-10T04:04:39.417836Z",
     "iopub.status.idle": "2025-10-10T04:04:39.424814Z",
     "shell.execute_reply": "2025-10-10T04:04:39.423366Z"
    },
    "papermill": {
     "duration": 0.018933,
     "end_time": "2025-10-10T04:04:39.427007",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.408074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_lags_rollings(df, col, group, lags=(1,2,3,6,12), windows=(3,6,12)):\n",
    "    df = df.copy()\n",
    "    g = df.groupby(group)[col]\n",
    "    for L in lags:\n",
    "        df[f\"{col}_lag{L}\"] = g.shift(L)\n",
    "    for W in windows:\n",
    "        df[f\"{col}_ma{W}\"] = g.shift(1).rolling(W, min_periods=1).mean()\n",
    "        df[f\"{col}_med{W}\"] = g.shift(1).rolling(W, min_periods=1).median()\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c3748ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.447845Z",
     "iopub.status.busy": "2025-10-10T04:04:39.447441Z",
     "iopub.status.idle": "2025-10-10T04:04:39.461460Z",
     "shell.execute_reply": "2025-10-10T04:04:39.460130Z"
    },
    "papermill": {
     "duration": 0.026429,
     "end_time": "2025-10-10T04:04:39.462871",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.436442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TARGET_COL = amount_new_house_transactions_nht\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def detect_amount_col_in_nht(df):\n",
    "    \"\"\"\n",
    "    在 new_house_transactions.csv 中自动寻找金额列。\n",
    "    优先匹配：'amount_new_house_transactions'、'new_house_transaction_amount'\n",
    "    否则：选择包含 'amount' 或 'transaction' 且不包含 'area'/'price' 的数值列。\n",
    "    \"\"\"\n",
    "    cols = df.columns.tolist()\n",
    "    preferred = [\"amount_new_house_transactions\", \"new_house_transaction_amount\"]\n",
    "    for name in preferred:\n",
    "        if name in df.columns and pd.api.types.is_numeric_dtype(df[name]):\n",
    "            return name\n",
    "\n",
    "    # 打分选择\n",
    "    cand = []\n",
    "    for c in cols:\n",
    "        lc = c.lower()\n",
    "        if not pd.api.types.is_numeric_dtype(df[c]):\n",
    "            continue\n",
    "        score = 0\n",
    "        if \"amount\" in lc: score += 10\n",
    "        if \"transact\" in lc or \"transaction\" in lc or \"txn\" in lc: score += 8\n",
    "        if \"house\" in lc and \"new\" in lc: score += 4\n",
    "        # 惩罚面积/价格类\n",
    "        if \"area\" in lc or \"price\" in lc or \"per_area\" in lc or \"avg\" in lc:\n",
    "            score -= 6\n",
    "        if score > 0:\n",
    "            cand.append((score, c))\n",
    "    if cand:\n",
    "        cand.sort(reverse=True)\n",
    "        return cand[0][1]\n",
    "    # 实在没有就选一个最可能的数值列（最后兜底）\n",
    "    num_cols = [c for c in cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not num_cols:\n",
    "        raise KeyError(\"在 nht 表中未找到任何数值型列，无法识别目标列。\")\n",
    "    return num_cols[0]\n",
    "\n",
    "# 1) 如果 base 中没有任何 *_nht 列，就从 nht 回填一个统一名字 target_nht\n",
    "nht_amount_src = detect_amount_col_in_nht(nht)\n",
    "if not any(col.endswith(\"_nht\") for col in base.columns):\n",
    "    base = base.merge(\n",
    "        nht[[\"time\", \"sector_id\", nht_amount_src]].rename(columns={nht_amount_src: \"target_nht\"}),\n",
    "        on=[\"time\", \"sector_id\"], how=\"left\"\n",
    "    )\n",
    "    TARGET_COL = \"target_nht\"\n",
    "else:\n",
    "    # 有 *_nht 就优先用匹配度最高的\n",
    "    def choose_best_nht_col(df):\n",
    "        cands = [c for c in df.columns if c.endswith(\"_nht\")]\n",
    "        def score(c):\n",
    "            s = c.lower()\n",
    "            sc = 0\n",
    "            if \"amount_new_house_transactions\" in s: sc += 10\n",
    "            if \"new_house_transaction_amount\" in s: sc += 9\n",
    "            if \"amount\" in s: sc += 5\n",
    "            if \"transaction\" in s or \"transact\" in s or \"txn\" in s: sc += 4\n",
    "            if \"area\" in s or \"price\" in s: sc -= 3\n",
    "            return sc\n",
    "        cands.sort(key=lambda x: (score(x), len(x)), reverse=True)\n",
    "        for c in cands:\n",
    "            if pd.api.types.is_numeric_dtype(df[c]):\n",
    "                return c\n",
    "        return cands[0]\n",
    "    TARGET_COL = choose_best_nht_col(base)\n",
    "\n",
    "print(\"Using TARGET_COL =\", TARGET_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "554e2cac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.481749Z",
     "iopub.status.busy": "2025-10-10T04:04:39.481435Z",
     "iopub.status.idle": "2025-10-10T04:04:39.489043Z",
     "shell.execute_reply": "2025-10-10T04:04:39.487818Z"
    },
    "papermill": {
     "duration": 0.018753,
     "end_time": "2025-10-10T04:04:39.490709",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.471956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aux columns: \n",
      "  NEIGHBOR_NHT_COL = amount_new_house_transactions_nearby_sectors_nhtns \n",
      "  PHT_BUILDING_COL = area_pre_owned_house_transactions_pht \n",
      "  LT_TRANS_AREA_COL = None\n"
     ]
    }
   ],
   "source": [
    "# 2) 可能用到的辅助列（存在才用）\n",
    "def find_optional_col(df, must_end=None, contains_any=()):\n",
    "    for c in df.columns:\n",
    "        if must_end and not c.endswith(must_end): \n",
    "            continue\n",
    "        s = c.lower()\n",
    "        if all(kw in s for kw in contains_any) and pd.api.types.is_numeric_dtype(df[c]):\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "NEIGHBOR_NHT_COL = find_optional_col(base, must_end=\"_nhtns\", contains_any=(\"amount\",))\n",
    "PHT_BUILDING_COL = (find_optional_col(base, must_end=\"_pht\", contains_any=(\"building\",\"area\"))\n",
    "                    or find_optional_col(base, must_end=\"_pht\", contains_any=(\"area\",)))\n",
    "LT_TRANS_AREA_COL = (find_optional_col(base, must_end=\"_ltns\", contains_any=(\"transacted\",\"area\"))\n",
    "                     or find_optional_col(base, must_end=\"_lt\", contains_any=(\"transacted\",\"area\")))\n",
    "\n",
    "print(\"Aux columns:\",\n",
    "      \"\\n  NEIGHBOR_NHT_COL =\", NEIGHBOR_NHT_COL,\n",
    "      \"\\n  PHT_BUILDING_COL =\", PHT_BUILDING_COL,\n",
    "      \"\\n  LT_TRANS_AREA_COL =\", LT_TRANS_AREA_COL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447e7a6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.510330Z",
     "iopub.status.busy": "2025-10-10T04:04:39.510018Z",
     "iopub.status.idle": "2025-10-10T04:04:39.536414Z",
     "shell.execute_reply": "2025-10-10T04:04:39.535172Z"
    },
    "papermill": {
     "duration": 0.038271,
     "end_time": "2025-10-10T04:04:39.538312",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.500041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3) 排序 & 构造标签（预测下个月 → shift(-1)）\n",
    "base = base.sort_values([\"sector_id\",\"time\"]).reset_index(drop=True)\n",
    "base[\"y\"] = base.groupby(\"sector_id\")[TARGET_COL].shift(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93e20e9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.557136Z",
     "iopub.status.busy": "2025-10-10T04:04:39.556800Z",
     "iopub.status.idle": "2025-10-10T04:04:39.630335Z",
     "shell.execute_reply": "2025-10-10T04:04:39.628482Z"
    },
    "papermill": {
     "duration": 0.085124,
     "end_time": "2025-10-10T04:04:39.632363",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.547239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4) 构造滞后/滚动特征（仅对存在列）\n",
    "def add_lags_rollings(df, col, group, lags=(1,2,3,6,12), windows=(3,6,12)):\n",
    "    df = df.copy()\n",
    "    g = df.groupby(group)[col]\n",
    "    for L in lags:\n",
    "        df[f\"{col}_lag{L}\"] = g.shift(L)\n",
    "    for W in windows:\n",
    "        df[f\"{col}_ma{W}\"] = g.shift(1).rolling(W, min_periods=1).mean()\n",
    "        df[f\"{col}_med{W}\"] = g.shift(1).rolling(W, min_periods=1).median()\n",
    "    return df\n",
    "\n",
    "base = add_lags_rollings(base, TARGET_COL, [\"sector_id\"], lags=(1,2,3,6,12), windows=(3,6,12))\n",
    "for col in [NEIGHBOR_NHT_COL, PHT_BUILDING_COL, LT_TRANS_AREA_COL]:\n",
    "    if col and (col in base.columns):\n",
    "        base = add_lags_rollings(base, col, [\"sector_id\"], lags=(1,2,6,12), windows=(3,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e41a8b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.650355Z",
     "iopub.status.busy": "2025-10-10T04:04:39.649977Z",
     "iopub.status.idle": "2025-10-10T04:04:39.679255Z",
     "shell.execute_reply": "2025-10-10T04:04:39.677273Z"
    },
    "papermill": {
     "duration": 0.040579,
     "end_time": "2025-10-10T04:04:39.681150",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.640571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5) 划分训练/测试\n",
    "train_df = base[base[\"time\"]<=66].copy()\n",
    "test_df  = base[(base[\"time\"]>=67)&(base[\"time\"]<=78)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "431b9554",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.698947Z",
     "iopub.status.busy": "2025-10-10T04:04:39.698389Z",
     "iopub.status.idle": "2025-10-10T04:04:39.705982Z",
     "shell.execute_reply": "2025-10-10T04:04:39.705102Z"
    },
    "papermill": {
     "duration": 0.018431,
     "end_time": "2025-10-10T04:04:39.707968",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.689537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6) 类别列\n",
    "CAT_COLS = [\"month_num\",\"qtr\"]\n",
    "for c in CAT_COLS:\n",
    "    if c in train_df.columns:\n",
    "        train_df[c] = train_df[c].astype(\"category\")\n",
    "    if c in test_df.columns:\n",
    "        test_df[c]  = test_df[c].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "516bd654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.727824Z",
     "iopub.status.busy": "2025-10-10T04:04:39.727419Z",
     "iopub.status.idle": "2025-10-10T04:04:39.733172Z",
     "shell.execute_reply": "2025-10-10T04:04:39.731671Z"
    },
    "papermill": {
     "duration": 0.017622,
     "end_time": "2025-10-10T04:04:39.735086",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.717464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7) 特征列（排除目标与键）\n",
    "DROP_COLS = {\"y\", TARGET_COL, \"time\", \"sector_id\", \"year\"}\n",
    "FEATURES = [c for c in train_df.columns if c not in DROP_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "529b019f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.754242Z",
     "iopub.status.busy": "2025-10-10T04:04:39.753878Z",
     "iopub.status.idle": "2025-10-10T04:04:39.797000Z",
     "shell.execute_reply": "2025-10-10T04:04:39.795350Z"
    },
    "papermill": {
     "duration": 0.053843,
     "end_time": "2025-10-10T04:04:39.798465",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.744622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 8) 二阶段目标\n",
    "# —— 训练 / 测试划分（已有）\n",
    "train_df = base[base[\"time\"]<=66].copy()\n",
    "test_df  = base[(base[\"time\"]>=67)&(base[\"time\"]<=78)].copy()\n",
    "\n",
    "# === 新增：清理标签与特征中的 NaN/Inf（在计算 y_pos 之前）===\n",
    "# 把正负无穷替换为 NaN\n",
    "for df in (train_df, test_df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 只保留 y 有真实值的训练样本（y 是由 shift(-1) 得来）\n",
    "train_df = train_df[train_df[\"y\"].notna()].copy()\n",
    "\n",
    "# （可选）若仍担心，有极端小概率 y < 0 的脏值时做裁剪\n",
    "train_df[\"y\"] = train_df[\"y\"].clip(lower=0)\n",
    "\n",
    "# 现在再生成二阶段分类标签就不会有警告了\n",
    "train_df[\"y_pos\"] = (train_df[\"y\"] > 0).astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9bb7c50b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.816101Z",
     "iopub.status.busy": "2025-10-10T04:04:39.815834Z",
     "iopub.status.idle": "2025-10-10T04:04:39.822014Z",
     "shell.execute_reply": "2025-10-10T04:04:39.820922Z"
    },
    "papermill": {
     "duration": 0.017677,
     "end_time": "2025-10-10T04:04:39.824115",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.806438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Baselines\n",
    "def ewgm(x, n_lags=6, alpha=0.6):\n",
    "    vals = np.asarray(x)[-n_lags:]\n",
    "    if len(vals)==0 or (vals>0).sum()==0:\n",
    "        return 0.0\n",
    "    w = np.array([alpha**(n_lags-1-i) for i in range(n_lags)], float)\n",
    "    w = w / w.sum()\n",
    "    pos = vals>0\n",
    "    if pos.sum()==0: \n",
    "        return 0.0\n",
    "    logv = np.log(np.where(vals[pos]<=0, 1e-12, vals[pos]))\n",
    "    ww = w[pos] / w[pos].sum()\n",
    "    return float(np.exp((ww*logv).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16467899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.842278Z",
     "iopub.status.busy": "2025-10-10T04:04:39.841885Z",
     "iopub.status.idle": "2025-10-10T04:04:39.849033Z",
     "shell.execute_reply": "2025-10-10T04:04:39.846987Z"
    },
    "papermill": {
     "duration": 0.018543,
     "end_time": "2025-10-10T04:04:39.850956",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.832413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def december_multipliers(wide_amount, clip=(0.85, 1.4)):\n",
    "    idx = wide_amount.index\n",
    "    is_dec = (idx % 12)==11\n",
    "    dec_mean = wide_amount[is_dec].mean(0)\n",
    "    other_mean = wide_amount[~is_dec].mean(0)\n",
    "    overall = dec_mean.mean()/(other_mean.mean()+1e-12)\n",
    "    mult = dec_mean/(other_mean+1e-12)\n",
    "    mult = mult.fillna(overall).replace([np.inf,-np.inf], 1.0)\n",
    "    return mult.clip(*clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12c6adad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.870047Z",
     "iopub.status.busy": "2025-10-10T04:04:39.869737Z",
     "iopub.status.idle": "2025-10-10T04:04:39.879773Z",
     "shell.execute_reply": "2025-10-10T04:04:39.878696Z"
    },
    "papermill": {
     "duration": 0.021915,
     "end_time": "2025-10-10T04:04:39.881989",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.860074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_baselines(df_all, df_te, value_col):\n",
    "    # ---- 1) 只保留需要的三列，并做去重聚合 ----\n",
    "    core = df_all.loc[:, [\"time\", \"sector_id\", value_col]].copy()\n",
    "    core = core.dropna(subset=[\"time\", \"sector_id\"])\n",
    "    core[\"time\"] = core[\"time\"].astype(int)\n",
    "    core[\"sector_id\"] = core[\"sector_id\"].astype(int)\n",
    "    core[value_col] = pd.to_numeric(core[value_col], errors=\"coerce\")\n",
    "\n",
    "    # 对 (time, sector_id) 去重聚合：取最大值（通常等同于“非空优先”）\n",
    "    # 也可以换成 .mean()，两者差别很小；max 对于含 NaN 的重复更稳\n",
    "    core = (\n",
    "        core.groupby([\"time\", \"sector_id\"], as_index=False)[value_col]\n",
    "            .max()\n",
    "    )\n",
    "\n",
    "    # ---- 2) 再 pivot，保证唯一性 ----\n",
    "    wide = core.pivot(index=\"time\", columns=\"sector_id\", values=value_col).fillna(0.0)\n",
    "\n",
    "    # ---- 3) 计算季节基线（与原逻辑一致）----\n",
    "    dec_mult = december_multipliers(wide)\n",
    "    idx_h = np.arange(67, 79)\n",
    "\n",
    "    # EWGM\n",
    "    ewgm_pred = pd.DataFrame(0.0, index=idx_h, columns=wide.columns)\n",
    "    for s in wide.columns:\n",
    "        ewgm_pred.loc[idx_h, s] = ewgm(wide[s].values, n_lags=12, alpha=0.6)\n",
    "\n",
    "    # Holt-Winters\n",
    "    from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "    hw_pred = pd.DataFrame(0.0, index=idx_h, columns=wide.columns)\n",
    "    for s in wide.columns:\n",
    "        arr = wide[s].values\n",
    "        try:\n",
    "            hw = ExponentialSmoothing(\n",
    "                arr, trend=\"add\", seasonal=\"add\", seasonal_periods=12,\n",
    "                initialization_method=\"estimated\"\n",
    "            ).fit()\n",
    "            f = hw.forecast(12)\n",
    "            hw_pred.loc[idx_h, s] = np.maximum(f, 0.0)\n",
    "        except Exception:\n",
    "            hw_pred.loc[idx_h, s] = np.maximum(arr[-1], 0.0)\n",
    "\n",
    "    # December bump\n",
    "    is_dec = (hw_pred.index % 12) == 11\n",
    "    hw_pred.loc[is_dec] = (hw_pred.loc[is_dec] * dec_mult).values\n",
    "    ewgm_pred.loc[is_dec] = (ewgm_pred.loc[is_dec] * dec_mult).values\n",
    "\n",
    "    # 展平成测试行顺序；df_te 即使有重复键也能对应映射\n",
    "    te_key = df_te[[\"time\", \"sector_id\"]].copy()\n",
    "    hw_flat = te_key.merge(\n",
    "        hw_pred.stack().rename(\"hw\").reset_index().rename(columns={\"level_1\": \"sector_id\"}),\n",
    "        on=[\"time\", \"sector_id\"], how=\"left\"\n",
    "    )[\"hw\"].values\n",
    "    ew_flat = te_key.merge(\n",
    "        ewgm_pred.stack().rename(\"ew\").reset_index().rename(columns={\"level_1\": \"sector_id\"}),\n",
    "        on=[\"time\", \"sector_id\"], how=\"left\"\n",
    "    )[\"ew\"].values\n",
    "\n",
    "    return hw_flat, ew_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "39e24784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.901946Z",
     "iopub.status.busy": "2025-10-10T04:04:39.901627Z",
     "iopub.status.idle": "2025-10-10T04:04:39.931196Z",
     "shell.execute_reply": "2025-10-10T04:04:39.929491Z"
    },
    "papermill": {
     "duration": 0.041562,
     "end_time": "2025-10-10T04:04:39.933173",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.891611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 统一清洗：替换inf为NaN，丢掉无标签行，裁剪负值 ---\n",
    "for df in (train_df, test_df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# 训练集只保留 y 有值的样本\n",
    "train_df = train_df[train_df[\"y\"].notna()].copy()\n",
    "train_df[\"y\"] = pd.to_numeric(train_df[\"y\"], errors=\"coerce\").clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee479f49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.951039Z",
     "iopub.status.busy": "2025-10-10T04:04:39.950632Z",
     "iopub.status.idle": "2025-10-10T04:04:39.958226Z",
     "shell.execute_reply": "2025-10-10T04:04:39.957373Z"
    },
    "papermill": {
     "duration": 0.018937,
     "end_time": "2025-10-10T04:04:39.960286",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.941349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- 面板去重聚合：避免一键多行 ---\n",
    "def dedupe_panel(df, key=(\"time\",\"sector_id\"), cat_cols=(\"month_num\",\"qtr\")):\n",
    "    df = df.copy()\n",
    "    # 保证键是整数\n",
    "    df[key[0]] = df[key[0]].astype(int)\n",
    "    df[key[1]] = df[key[1]].astype(int)\n",
    "\n",
    "    # 数值列和类别列识别\n",
    "    num_cols = [c for c in df.columns if c not in key and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    # —— 关键：把“看起来是数字但变成了 object”的列也转回数值 —— #\n",
    "    for c in df.columns:\n",
    "        if c not in key and df[c].dtype == \"object\":\n",
    "            # 尝试转为数值；失败则变 NaN（不会影响聚合）\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    num_cols = [c for c in df.columns if c not in key and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "    agg = {c: \"mean\" for c in num_cols}\n",
    "    for c in cat_cols:\n",
    "        agg[c] = \"first\"\n",
    "\n",
    "    df = df.groupby(list(key), as_index=False).agg(agg)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe18cacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:39.980550Z",
     "iopub.status.busy": "2025-10-10T04:04:39.980253Z",
     "iopub.status.idle": "2025-10-10T04:04:40.123661Z",
     "shell.execute_reply": "2025-10-10T04:04:40.122175Z"
    },
    "papermill": {
     "duration": 0.155832,
     "end_time": "2025-10-10T04:04:40.125203",
     "exception": false,
     "start_time": "2025-10-10T04:04:39.969371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = dedupe_panel(train_df)\n",
    "test_df  = dedupe_panel(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfd02cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.142648Z",
     "iopub.status.busy": "2025-10-10T04:04:40.142259Z",
     "iopub.status.idle": "2025-10-10T04:04:40.148346Z",
     "shell.execute_reply": "2025-10-10T04:04:40.147213Z"
    },
    "papermill": {
     "duration": 0.016787,
     "end_time": "2025-10-10T04:04:40.149877",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.133090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings, numpy as np, pandas as pd\n",
    "\n",
    "# 遇到 NaN 与比较时不再警告（只针对这类 runtime）\n",
    "np.seterr(invalid=\"ignore\")\n",
    "\n",
    "# 把这类警告都忽略（仅显示层面）\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered.*\")\n",
    "\n",
    "# 统一浮点显示（可选）\n",
    "pd.options.display.float_format = lambda x: f\"{x:.6f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c703f9b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.169123Z",
     "iopub.status.busy": "2025-10-10T04:04:40.168850Z",
     "iopub.status.idle": "2025-10-10T04:04:40.174788Z",
     "shell.execute_reply": "2025-10-10T04:04:40.173217Z"
    },
    "papermill": {
     "duration": 0.017334,
     "end_time": "2025-10-10T04:04:40.176597",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.159263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings, numpy as np, pandas as pd\n",
    "np.seterr(invalid=\"ignore\")  # 避免 NaN 比较时的 runtime 警告\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered.*\")\n",
    "pd.options.display.float_format = lambda x: f\"{x:.6f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a347cced",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.195152Z",
     "iopub.status.busy": "2025-10-10T04:04:40.193577Z",
     "iopub.status.idle": "2025-10-10T04:04:40.201974Z",
     "shell.execute_reply": "2025-10-10T04:04:40.200470Z"
    },
    "papermill": {
     "duration": 0.019567,
     "end_time": "2025-10-10T04:04:40.204195",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.184628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 更稳的去重聚合（将 object 数值列转回 numeric 再 groupby）----\n",
    "def dedupe_panel(df, key=(\"time\",\"sector_id\"), cat_cols=(\"month_num\",\"qtr\")):\n",
    "    df = df.copy()\n",
    "    df[key[0]] = df[key[0]].astype(int)\n",
    "    df[key[1]] = df[key[1]].astype(int)\n",
    "    # 把“看起来是数字却是 object”的列转为数值\n",
    "    for c in df.columns:\n",
    "        if c not in key and df[c].dtype == \"object\":\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    # 聚合：数值均值、分类取第一条\n",
    "    num_cols = [c for c in df.columns if c not in key and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    agg = {c: \"mean\" for c in num_cols}\n",
    "    for c in cat_cols:\n",
    "        if c in df.columns:\n",
    "            agg[c] = \"first\"\n",
    "    return df.groupby(list(key), as_index=False).agg(agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0e2a85f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.223588Z",
     "iopub.status.busy": "2025-10-10T04:04:40.223299Z",
     "iopub.status.idle": "2025-10-10T04:04:40.233188Z",
     "shell.execute_reply": "2025-10-10T04:04:40.231708Z"
    },
    "papermill": {
     "duration": 0.021531,
     "end_time": "2025-10-10T04:04:40.235441",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.213910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 基础清洗 ----\n",
    "for df in (train_df, test_df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e67616ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.253220Z",
     "iopub.status.busy": "2025-10-10T04:04:40.252928Z",
     "iopub.status.idle": "2025-10-10T04:04:40.262663Z",
     "shell.execute_reply": "2025-10-10T04:04:40.260787Z"
    },
    "papermill": {
     "duration": 0.020438,
     "end_time": "2025-10-10T04:04:40.264497",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.244059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 训练集仅保留有标签的样本，并裁掉负值\n",
    "train_df = train_df[train_df[\"y\"].notna()].copy()\n",
    "train_df[\"y\"] = pd.to_numeric(train_df[\"y\"], errors=\"coerce\").clip(lower=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fef99470",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.282533Z",
     "iopub.status.busy": "2025-10-10T04:04:40.282221Z",
     "iopub.status.idle": "2025-10-10T04:04:40.391140Z",
     "shell.execute_reply": "2025-10-10T04:04:40.389420Z"
    },
    "papermill": {
     "duration": 0.119943,
     "end_time": "2025-10-10T04:04:40.392927",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.272984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 去重聚合，确保一键一行\n",
    "train_df = dedupe_panel(train_df)\n",
    "test_df  = dedupe_panel(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "147df5d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.410959Z",
     "iopub.status.busy": "2025-10-10T04:04:40.410487Z",
     "iopub.status.idle": "2025-10-10T04:04:40.423341Z",
     "shell.execute_reply": "2025-10-10T04:04:40.421914Z"
    },
    "papermill": {
     "duration": 0.023691,
     "end_time": "2025-10-10T04:04:40.424917",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.401226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 类别列 ----\n",
    "CAT_COLS = [c for c in [\"month_num\",\"qtr\"] if c in train_df.columns]\n",
    "for c in CAT_COLS:\n",
    "    train_df[c] = train_df[c].astype(\"category\")\n",
    "    if c in test_df.columns:\n",
    "        test_df[c] = test_df[c].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ca75140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.441892Z",
     "iopub.status.busy": "2025-10-10T04:04:40.441629Z",
     "iopub.status.idle": "2025-10-10T04:04:40.447851Z",
     "shell.execute_reply": "2025-10-10T04:04:40.445787Z"
    },
    "papermill": {
     "duration": 0.016953,
     "end_time": "2025-10-10T04:04:40.449825",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.432872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 特征列（去掉目标与主键）----\n",
    "DROP_COLS = {\"y\", \"time\", \"sector_id\", \"year\"}\n",
    "if TARGET_COL in train_df.columns:\n",
    "    DROP_COLS.add(TARGET_COL)\n",
    "FEATURES = [c for c in train_df.columns if c not in DROP_COLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "405118c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.469448Z",
     "iopub.status.busy": "2025-10-10T04:04:40.469194Z",
     "iopub.status.idle": "2025-10-10T04:04:40.482432Z",
     "shell.execute_reply": "2025-10-10T04:04:40.480788Z"
    },
    "papermill": {
     "duration": 0.024618,
     "end_time": "2025-10-10T04:04:40.484698",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.460080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_baselines(df_all, df_te, value_col):\n",
    "    \"\"\"\n",
    "    先对 (time, sector_id) 去重聚合，再 pivot 得 wide；\n",
    "    生成 EWGM 和 Holt-Winters 12 期预测；\n",
    "    用 melt 显式产出带 ['time','sector_id'] 的长表，与 test_df 键合并。\n",
    "    \"\"\"\n",
    "    # ---- 1) 去重聚合，保证一键一值 ----\n",
    "    core = df_all.loc[:, [\"time\", \"sector_id\", value_col]].copy()\n",
    "    core = core.dropna(subset=[\"time\", \"sector_id\"])\n",
    "    core[\"time\"] = core[\"time\"].astype(int)\n",
    "    core[\"sector_id\"] = core[\"sector_id\"].astype(int)\n",
    "    core[value_col] = pd.to_numeric(core[value_col], errors=\"coerce\")\n",
    "\n",
    "    # 聚合：max 或 mean 都可；max 对含 NaN 的重复更稳\n",
    "    core = core.groupby([\"time\", \"sector_id\"], as_index=False)[value_col].max()\n",
    "\n",
    "    # ---- 2) 透视成 wide[time x sector] ----\n",
    "    wide = core.pivot(index=\"time\", columns=\"sector_id\", values=value_col).fillna(0.0)\n",
    "    wide = wide.sort_index()\n",
    "    wide.columns = wide.columns.astype(int)\n",
    "\n",
    "    # ---- 3) 计算 December bump ----\n",
    "    dec_mult = december_multipliers(wide)\n",
    "    idx_h = np.arange(67, 79)\n",
    "\n",
    "    # ---- 4) EWGM 预测 ----\n",
    "    ewgm_pred = pd.DataFrame(0.0, index=idx_h, columns=wide.columns, dtype=float)\n",
    "    for s in wide.columns:\n",
    "        ewgm_pred.loc[idx_h, s] = ewgm(wide[s].values, n_lags=12, alpha=0.6)\n",
    "    # 命名 index/columns，避免后续列名缺失\n",
    "    ewgm_pred.index.name = \"time\"\n",
    "    ewgm_pred.columns.name = \"sector_id\"\n",
    "\n",
    "    # ---- 5) Holt-Winters 预测（不收敛时回退为最后值）----\n",
    "    from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "    hw_pred = pd.DataFrame(0.0, index=idx_h, columns=wide.columns, dtype=float)\n",
    "    for s in wide.columns:\n",
    "        arr = wide[s].astype(float).values\n",
    "        try:\n",
    "            model = ExponentialSmoothing(\n",
    "                arr, trend=\"add\", seasonal=\"add\", seasonal_periods=12,\n",
    "                initialization_method=\"estimated\"\n",
    "            ).fit()\n",
    "            f = model.forecast(12)\n",
    "            hw_pred.loc[idx_h, s] = np.maximum(f, 0.0)\n",
    "        except Exception:\n",
    "            hw_pred.loc[idx_h, s] = np.maximum(arr[-1], 0.0)\n",
    "    hw_pred.index.name = \"time\"\n",
    "    hw_pred.columns.name = \"sector_id\"\n",
    "\n",
    "    # ---- 6) 应用 December bump（已按列对齐）----\n",
    "    is_dec = (ewgm_pred.index % 12) == 11\n",
    "    # 将 dec_mult 对齐列\n",
    "    dec_mult = dec_mult.reindex(hw_pred.columns).fillna(1.0)\n",
    "    if is_dec.any():\n",
    "        # 行向量 * 列向量的广播：给 12 月的行乘以每个 sector 的 multiplier\n",
    "        hw_pred.loc[is_dec, :] = hw_pred.loc[is_dec, :].values * dec_mult.values\n",
    "        ewgm_pred.loc[is_dec, :] = ewgm_pred.loc[is_dec, :].values * dec_mult.values\n",
    "\n",
    "    # ---- 7) 展平成带键的长表（显式列名），与 test_df 键合并 ----\n",
    "    hw_long = (hw_pred.reset_index()\n",
    "                      .melt(id_vars=\"time\", var_name=\"sector_id\", value_name=\"hw\"))\n",
    "    ew_long = (ewgm_pred.reset_index()\n",
    "                        .melt(id_vars=\"time\", var_name=\"sector_id\", value_name=\"ew\"))\n",
    "    hw_long[\"sector_id\"] = hw_long[\"sector_id\"].astype(int)\n",
    "    ew_long[\"sector_id\"] = ew_long[\"sector_id\"].astype(int)\n",
    "\n",
    "    te_key = df_te[[\"time\", \"sector_id\"]].copy()\n",
    "    te_key[\"time\"] = te_key[\"time\"].astype(int)\n",
    "    te_key[\"sector_id\"] = te_key[\"sector_id\"].astype(int)\n",
    "\n",
    "    hw_flat = te_key.merge(hw_long, on=[\"time\", \"sector_id\"], how=\"left\")[\"hw\"].to_numpy()\n",
    "    ew_flat = te_key.merge(ew_long, on=[\"time\", \"sector_id\"], how=\"left\")[\"ew\"].to_numpy()\n",
    "\n",
    "    # 缺失就补 0（很少见，通常键全能对上）\n",
    "    hw_flat = np.nan_to_num(hw_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    ew_flat = np.nan_to_num(ew_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return hw_flat, ew_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "71c9e2e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:40.503972Z",
     "iopub.status.busy": "2025-10-10T04:04:40.503703Z",
     "iopub.status.idle": "2025-10-10T04:04:48.668806Z",
     "shell.execute_reply": "2025-10-10T04:04:48.665984Z"
    },
    "papermill": {
     "duration": 8.176679,
     "end_time": "2025-10-10T04:04:48.670875",
     "exception": false,
     "start_time": "2025-10-10T04:04:40.494196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/holtwinters/model.py:903: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/holtwinters/model.py:1380: RuntimeWarning: divide by zero encountered in log\n",
      "  aic = self.nobs * np.log(sse / self.nobs) + k * 2\n",
      "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/holtwinters/model.py:1387: RuntimeWarning: divide by zero encountered in log\n",
      "  bic = self.nobs * np.log(sse / self.nobs) + k * np.log(self.nobs)\n",
      "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/holtwinters/model.py:1380: RuntimeWarning: divide by zero encountered in log\n",
      "  aic = self.nobs * np.log(sse / self.nobs) + k * 2\n",
      "/usr/local/lib/python3.11/dist-packages/statsmodels/tsa/holtwinters/model.py:1387: RuntimeWarning: divide by zero encountered in log\n",
      "  bic = self.nobs * np.log(sse / self.nobs) + k * np.log(self.nobs)\n"
     ]
    }
   ],
   "source": [
    "# 生成季节基线\n",
    "hw_te, ew_te = build_baselines(base, test_df, TARGET_COL)\n",
    "\n",
    "# ……你之前的后处理与提交流程保持不变……\n",
    "# 二分类门控 + 收缩 + caps → final_pred\n",
    "# 按键合并到 test.csv 行序 → 保存 submission.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16edec6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.696836Z",
     "iopub.status.busy": "2025-10-10T04:04:48.696235Z",
     "iopub.status.idle": "2025-10-10T04:04:48.703102Z",
     "shell.execute_reply": "2025-10-10T04:04:48.702433Z"
    },
    "papermill": {
     "duration": 0.021287,
     "end_time": "2025-10-10T04:04:48.704923",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.683636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====== 安全收尾：若缺少预测则即时训练，然后完成后处理与提交 ======\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "\n",
    "# 1) 如未计算季节基线，则先计算\n",
    "if \"hw_te\" not in globals() or \"ew_te\" not in globals():\n",
    "    hw_te, ew_te = build_baselines(base, test_df, TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60e94446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.731571Z",
     "iopub.status.busy": "2025-10-10T04:04:48.729946Z",
     "iopub.status.idle": "2025-10-10T04:04:48.751789Z",
     "shell.execute_reply": "2025-10-10T04:04:48.750978Z"
    },
    "papermill": {
     "duration": 0.036571,
     "end_time": "2025-10-10T04:04:48.753831",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.717260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_two_stage_and_predict(train_df, test_df, FEATURES=None, CAT_COLS=None,\n",
    "                                n_splits=4, seed=42):\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "\n",
    "    # 1) 特征/类别列（更稳：仅用 train/test 公共列；显式排除非特征）\n",
    "    if FEATURES is None:\n",
    "        drop = {\"y\", \"y_pos\", \"time\", \"sector_id\", \"year\", \"pred\"}\n",
    "        if \"TARGET_COL\" in globals() and TARGET_COL in train_df.columns:\n",
    "            drop.add(TARGET_COL)\n",
    "        common_cols = [c for c in train_df.columns if c in test_df.columns]\n",
    "        FEATURES = [c for c in common_cols if c not in drop]\n",
    "\n",
    "    if CAT_COLS is None:\n",
    "        # 只保留也在 FEATURES 里的类别列\n",
    "        guess_cats = [c for c in [\"month_num\", \"qtr\"] if c in FEATURES]\n",
    "        CAT_COLS = guess_cats\n",
    "\n",
    "    # 统一类别 dtype\n",
    "    for c in CAT_COLS:\n",
    "        if c in train_df.columns and not pd.api.types.is_categorical_dtype(train_df[c]):\n",
    "            train_df[c] = train_df[c].astype(\"category\")\n",
    "        if c in test_df.columns and not pd.api.types.is_categorical_dtype(test_df[c]):\n",
    "            test_df[c] = test_df[c].astype(\"category\")\n",
    "\n",
    "    # 2) 构造 X/X_te：数值与类别分开处理\n",
    "    def make_X(df):\n",
    "        X = df[FEATURES].copy()\n",
    "\n",
    "        # object→numeric（能转就转，失败置 NaN）\n",
    "        for c in X.columns:\n",
    "            if c in CAT_COLS:\n",
    "                continue\n",
    "            if X[c].dtype == \"object\":\n",
    "                X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "\n",
    "        # 数值列填 -2\n",
    "        num_cols = [c for c in X.columns if (c not in CAT_COLS) and pd.api.types.is_numeric_dtype(X[c])]\n",
    "        if num_cols:\n",
    "            X[num_cols] = (X[num_cols]\n",
    "                           .replace([np.inf, -np.inf], np.nan)\n",
    "                           .astype(float)\n",
    "                           .fillna(-2.0))\n",
    "\n",
    "        # 类别列填 \"__MISSING__\"\n",
    "        for c in CAT_COLS:\n",
    "            if c in X.columns:\n",
    "                X[c] = X[c].cat.add_categories([\"__MISSING__\"]).fillna(\"__MISSING__\")\n",
    "\n",
    "        return X\n",
    "\n",
    "    X    = make_X(train_df)\n",
    "    X_te = make_X(test_df)\n",
    "\n",
    "    # 3) 列对齐（补缺/删多，顺序一致）\n",
    "    for c in X.columns:\n",
    "        if c not in X_te.columns:\n",
    "            if c in CAT_COLS:\n",
    "                s = pd.Series([\"__MISSING__\"]*len(X_te), index=X_te.index, dtype=\"object\")\n",
    "                s = s.astype(\"category\")\n",
    "                X_te[c] = s\n",
    "                X_te[c] = X_te[c].cat.add_categories([\"__MISSING__\"]).fillna(\"__MISSING__\")\n",
    "            else:\n",
    "                X_te[c] = -2.0\n",
    "    # 仅保留 X 中的列并按顺序排列\n",
    "    X_te = X_te[X.columns]\n",
    "\n",
    "    y     = train_df[\"y\"].to_numpy()\n",
    "    y_pos = (train_df[\"y\"] > 0).astype(int).to_numpy()\n",
    "\n",
    "    # 4) 时序 CV 训练与预测\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    pred_test_reg  = np.zeros((len(X_te), n_splits))\n",
    "    pred_test_posp = np.zeros((len(X_te), n_splits))\n",
    "\n",
    "    for k, (tr_idx, va_idx) in enumerate(tscv.split(X, y)):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "        p_tr, p_va = y_pos[tr_idx], y_pos[va_idx]\n",
    "\n",
    "        # —— 分类器：P(y>0)\n",
    "        clf = CatBoostClassifier(\n",
    "            depth=6, learning_rate=0.04, iterations=4000,\n",
    "            loss_function=\"Logloss\", eval_metric=\"AUC\",\n",
    "            l2_leaf_reg=3.0, random_seed=seed, verbose=False\n",
    "        )\n",
    "        clf.fit(Pool(X_tr, p_tr, cat_features=CAT_COLS),\n",
    "                eval_set=Pool(X_va, p_va, cat_features=CAT_COLS),\n",
    "                verbose=False)\n",
    "        pred_test_posp[:, k] = clf.predict_proba(X_te)[:, 1]\n",
    "\n",
    "        # —— 回归器：log1p(y) on positives\n",
    "        mask_tr = y_tr > 0\n",
    "        reg = CatBoostRegressor(\n",
    "            depth=8, learning_rate=0.03, iterations=6000,\n",
    "            loss_function=\"MAE\", eval_metric=\"MAE\",\n",
    "            l2_leaf_reg=2.0, random_seed=seed + k, verbose=False\n",
    "        )\n",
    "        reg.fit(Pool(X_tr[mask_tr], np.log1p(y_tr[mask_tr]), cat_features=CAT_COLS),\n",
    "                eval_set=Pool(X_va, np.log1p(np.maximum(y_va, 0)), cat_features=CAT_COLS),\n",
    "                verbose=False)\n",
    "        pred_test_reg[:, k] = np.expm1(np.maximum(reg.predict(X_te), 0.0))\n",
    "\n",
    "    reg_te  = pred_test_reg.mean(axis=1)\n",
    "    posp_te = pred_test_posp.mean(axis=1)\n",
    "    return reg_te, posp_te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "144f2a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.775099Z",
     "iopub.status.busy": "2025-10-10T04:04:48.774769Z",
     "iopub.status.idle": "2025-10-10T04:04:48.779970Z",
     "shell.execute_reply": "2025-10-10T04:04:48.778886Z"
    },
    "papermill": {
     "duration": 0.017615,
     "end_time": "2025-10-10T04:04:48.782495",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.764880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ====================== 一键收尾：从此格开始跑到生成 submission.csv ======================\n",
    "import warnings, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ab6cb24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.799975Z",
     "iopub.status.busy": "2025-10-10T04:04:48.799704Z",
     "iopub.status.idle": "2025-10-10T04:04:48.805280Z",
     "shell.execute_reply": "2025-10-10T04:04:48.803859Z"
    },
    "papermill": {
     "duration": 0.016078,
     "end_time": "2025-10-10T04:04:48.807168",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.791090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 显示层与数值清理（压掉无害警告）----\n",
    "np.seterr(invalid=\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"Optimization failed to converge.*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6e4ca0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.827623Z",
     "iopub.status.busy": "2025-10-10T04:04:48.827286Z",
     "iopub.status.idle": "2025-10-10T04:04:48.832365Z",
     "shell.execute_reply": "2025-10-10T04:04:48.831070Z"
    },
    "papermill": {
     "duration": 0.016387,
     "end_time": "2025-10-10T04:04:48.833741",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.817354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 路径兜底 ----\n",
    "try:\n",
    "    OUT\n",
    "except NameError:\n",
    "    OUT = Path(\"/kaggle/working\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a824ce79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.852836Z",
     "iopub.status.busy": "2025-10-10T04:04:48.852492Z",
     "iopub.status.idle": "2025-10-10T04:04:48.859498Z",
     "shell.execute_reply": "2025-10-10T04:04:48.858246Z"
    },
    "papermill": {
     "duration": 0.018415,
     "end_time": "2025-10-10T04:04:48.861310",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.842895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 兜底工具：去重聚合、拆分 test id、December bump、EWGM ----\n",
    "def dedupe_panel(df, key=(\"time\",\"sector_id\"), cat_cols=(\"month_num\",\"qtr\")):\n",
    "    df = df.copy()\n",
    "    df[key[0]] = df[key[0]].astype(int)\n",
    "    df[key[1]] = df[key[1]].astype(int)\n",
    "    # object→numeric\n",
    "    for c in df.columns:\n",
    "        if c not in key and df[c].dtype == \"object\":\n",
    "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    num_cols = [c for c in df.columns if c not in key and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    agg = {c: \"mean\" for c in num_cols}\n",
    "    for c in cat_cols:\n",
    "        if c in df.columns:\n",
    "            agg[c] = \"first\"\n",
    "    return df.groupby(list(key), as_index=False).agg(agg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fade4e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.877963Z",
     "iopub.status.busy": "2025-10-10T04:04:48.877706Z",
     "iopub.status.idle": "2025-10-10T04:04:48.883291Z",
     "shell.execute_reply": "2025-10-10T04:04:48.882350Z"
    },
    "papermill": {
     "duration": 0.016339,
     "end_time": "2025-10-10T04:04:48.885605",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.869266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_test_id(test):\n",
    "    MONTH2NUM = dict(Jan=1, Feb=2, Mar=3, Apr=4, May=5, Jun=6,\n",
    "                     Jul=7, Aug=8, Sep=9, Oct=10, Nov=11, Dec=12)\n",
    "    parts = test[\"id\"].str.split(\"_\", expand=True)\n",
    "    test[\"month_text\"] = parts[0]\n",
    "    test[\"sector\"] = parts[1]\n",
    "    test[\"sector_id\"] = test[\"sector\"].str.replace(\"sector \", \"\", regex=False).astype(int)\n",
    "    test[\"year\"] = test[\"month_text\"].str.slice(0, 4).astype(int)\n",
    "    test[\"month_num\"] = test[\"month_text\"].str.slice(5).map(MONTH2NUM).astype(int)\n",
    "    test[\"time\"] = (test[\"year\"] - 2019) * 12 + test[\"month_num\"] - 1\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d6eae60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.905112Z",
     "iopub.status.busy": "2025-10-10T04:04:48.904627Z",
     "iopub.status.idle": "2025-10-10T04:04:48.911377Z",
     "shell.execute_reply": "2025-10-10T04:04:48.909741Z"
    },
    "papermill": {
     "duration": 0.017959,
     "end_time": "2025-10-10T04:04:48.913120",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.895161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ewgm(arr, n_lags=12, alpha=0.6):\n",
    "    v = np.asarray(arr)[-n_lags:]\n",
    "    if v.size == 0 or (v>0).sum()==0:\n",
    "        return 0.0\n",
    "    w = np.array([alpha**(n_lags-1-i) for i in range(n_lags)], float)\n",
    "    w = w / w.sum()\n",
    "    pos = v>0\n",
    "    if pos.sum()==0: \n",
    "        return 0.0\n",
    "    logv = np.log(np.where(v[pos]<=0, 1e-12, v[pos]))\n",
    "    ww = w[pos] / w[pos].sum()\n",
    "    return float(np.exp((ww*logv).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c9d9775a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.930171Z",
     "iopub.status.busy": "2025-10-10T04:04:48.929887Z",
     "iopub.status.idle": "2025-10-10T04:04:48.935306Z",
     "shell.execute_reply": "2025-10-10T04:04:48.934080Z"
    },
    "papermill": {
     "duration": 0.015711,
     "end_time": "2025-10-10T04:04:48.936839",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.921128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def december_multipliers(wide, clip=(0.85, 1.4)):\n",
    "    is_dec = (wide.index % 12) == 11\n",
    "    dm = wide[is_dec].mean(0)\n",
    "    om = wide[~is_dec].mean(0)\n",
    "    overall = dm.mean()/(om.mean()+1e-12)\n",
    "    mult = (dm/(om+1e-12)).fillna(overall).replace([np.inf,-np.inf], 1.0)\n",
    "    return mult.clip(*clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e5c26997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.953479Z",
     "iopub.status.busy": "2025-10-10T04:04:48.953252Z",
     "iopub.status.idle": "2025-10-10T04:04:48.964484Z",
     "shell.execute_reply": "2025-10-10T04:04:48.962975Z"
    },
    "papermill": {
     "duration": 0.021496,
     "end_time": "2025-10-10T04:04:48.966408",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.944912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 若未定义 build_baselines，则定义为“melt + 显式键名”的稳健版 ----\n",
    "if \"build_baselines\" not in globals():\n",
    "    from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "    def build_baselines(df_all, df_te, value_col):\n",
    "        core = df_all.loc[:, [\"time\", \"sector_id\", value_col]].copy()\n",
    "        core = core.dropna(subset=[\"time\",\"sector_id\"])\n",
    "        core[\"time\"] = core[\"time\"].astype(int)\n",
    "        core[\"sector_id\"] = core[\"sector_id\"].astype(int)\n",
    "        core[value_col] = pd.to_numeric(core[value_col], errors=\"coerce\")\n",
    "        core = core.groupby([\"time\",\"sector_id\"], as_index=False)[value_col].max()\n",
    "\n",
    "        wide = core.pivot(index=\"time\", columns=\"sector_id\", values=value_col).fillna(0.0)\n",
    "        wide = wide.sort_index()\n",
    "        wide.columns = wide.columns.astype(int)\n",
    "\n",
    "        dec_mult = december_multipliers(wide)\n",
    "        idx_h = np.arange(67,79)\n",
    "\n",
    "        ewgm_pred = pd.DataFrame(0.0, index=idx_h, columns=wide.columns, dtype=float)\n",
    "        for s in wide.columns:\n",
    "            ewgm_pred.loc[idx_h, s] = ewgm(wide[s].values, n_lags=12, alpha=0.6)\n",
    "        ewgm_pred.index.name = \"time\"; ewgm_pred.columns.name = \"sector_id\"\n",
    "\n",
    "        hw_pred = pd.DataFrame(0.0, index=idx_h, columns=wide.columns, dtype=float)\n",
    "        for s in wide.columns:\n",
    "            arr = wide[s].astype(float).values\n",
    "            try:\n",
    "                model = ExponentialSmoothing(arr, trend=\"add\", seasonal=\"add\",\n",
    "                                             seasonal_periods=12,\n",
    "                                             initialization_method=\"estimated\").fit()\n",
    "                f = model.forecast(12)\n",
    "                hw_pred.loc[idx_h, s] = np.maximum(f, 0.0)\n",
    "            except Exception:\n",
    "                hw_pred.loc[idx_h, s] = np.maximum(arr[-1], 0.0)\n",
    "        hw_pred.index.name = \"time\"; hw_pred.columns.name = \"sector_id\"\n",
    "\n",
    "        is_dec = (ewgm_pred.index % 12) == 11\n",
    "        dec_mult = dec_mult.reindex(hw_pred.columns).fillna(1.0)\n",
    "        if is_dec.any():\n",
    "            hw_pred.loc[is_dec, :] = hw_pred.loc[is_dec, :].values * dec_mult.values\n",
    "            ewgm_pred.loc[is_dec, :] = ewgm_pred.loc[is_dec, :].values * dec_mult.values\n",
    "\n",
    "        hw_long = hw_pred.reset_index().melt(id_vars=\"time\", var_name=\"sector_id\", value_name=\"hw\")\n",
    "        ew_long = ewgm_pred.reset_index().melt(id_vars=\"time\", var_name=\"sector_id\", value_name=\"ew\")\n",
    "        hw_long[\"sector_id\"] = hw_long[\"sector_id\"].astype(int)\n",
    "        ew_long[\"sector_id\"] = ew_long[\"sector_id\"].astype(int)\n",
    "\n",
    "        te_key = df_te[[\"time\",\"sector_id\"]].copy().astype(int)\n",
    "        hw_flat = te_key.merge(hw_long, on=[\"time\",\"sector_id\"], how=\"left\")[\"hw\"].to_numpy()\n",
    "        ew_flat = te_key.merge(ew_long, on=[\"time\",\"sector_id\"], how=\"left\")[\"ew\"].to_numpy()\n",
    "        hw_flat = np.nan_to_num(hw_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        ew_flat = np.nan_to_num(ew_flat, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        return hw_flat, ew_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "69bc6e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:48.985303Z",
     "iopub.status.busy": "2025-10-10T04:04:48.985045Z",
     "iopub.status.idle": "2025-10-10T04:04:49.001907Z",
     "shell.execute_reply": "2025-10-10T04:04:49.000414Z"
    },
    "papermill": {
     "duration": 0.02847,
     "end_time": "2025-10-10T04:04:49.003857",
     "exception": false,
     "start_time": "2025-10-10T04:04:48.975387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- 训练函数（修好类别/数值填充 & 列对齐）----\n",
    "def train_two_stage_and_predict(train_df, test_df, FEATURES=None, CAT_COLS=None,\n",
    "                                n_splits=4, seed=42,\n",
    "                                default_reg_pred=None,  # 建议传 ew_te\n",
    "                                default_posp=None):     # 可不传，用全局阳性率\n",
    "    import pandas as pd, numpy as np\n",
    "    from sklearn.model_selection import TimeSeriesSplit\n",
    "    from catboost import CatBoostRegressor, CatBoostClassifier, Pool\n",
    "\n",
    "    # 1) 特征/类别列（仅取 train/test 交集，显式排除非特征）\n",
    "    if FEATURES is None:\n",
    "        drop = {\"y\", \"y_pos\", \"time\", \"sector_id\", \"year\", \"pred\"}\n",
    "        if \"TARGET_COL\" in globals() and TARGET_COL in train_df.columns:\n",
    "            drop.add(TARGET_COL)\n",
    "        common = [c for c in train_df.columns if c in test_df.columns]\n",
    "        FEATURES = [c for c in common if c not in drop]\n",
    "    if CAT_COLS is None:\n",
    "        CAT_COLS = [c for c in [\"month_num\", \"qtr\"] if c in FEATURES]\n",
    "\n",
    "    # 统一类别 dtype\n",
    "    for c in CAT_COLS:\n",
    "        if c in train_df and not pd.api.types.is_categorical_dtype(train_df[c]):\n",
    "            train_df[c] = train_df[c].astype(\"category\")\n",
    "        if c in test_df and not pd.api.types.is_categorical_dtype(test_df[c]):\n",
    "            test_df[c] = test_df[c].astype(\"category\")\n",
    "\n",
    "    # 2) 构造特征矩阵（数值/类别分开处理）\n",
    "    def make_X(df):\n",
    "        X = df[FEATURES].copy()\n",
    "        for c in X.columns:\n",
    "            if c in CAT_COLS: \n",
    "                continue\n",
    "            if X[c].dtype == \"object\":\n",
    "                X[c] = pd.to_numeric(X[c], errors=\"coerce\")\n",
    "        num_cols = [c for c in X.columns if (c not in CAT_COLS) and pd.api.types.is_numeric_dtype(X[c])]\n",
    "        if num_cols:\n",
    "            X[num_cols] = (X[num_cols].replace([np.inf,-np.inf], np.nan).astype(float).fillna(-2.0))\n",
    "        for c in CAT_COLS:\n",
    "            if c in X.columns:\n",
    "                X[c] = X[c].cat.add_categories([\"__MISSING__\"]).fillna(\"__MISSING__\")\n",
    "        return X\n",
    "\n",
    "    X    = make_X(train_df)\n",
    "    X_te = make_X(test_df)\n",
    "\n",
    "    # 列对齐\n",
    "    for c in X.columns:\n",
    "        if c not in X_te.columns:\n",
    "            if c in CAT_COLS:\n",
    "                s = pd.Series([\"__MISSING__\"]*len(X_te), index=X_te.index, dtype=\"object\").astype(\"category\")\n",
    "                X_te[c] = s.cat.add_categories([\"__MISSING__\"]).fillna(\"__MISSING__\")\n",
    "            else:\n",
    "                X_te[c] = -2.0\n",
    "    X_te = X_te[X.columns]\n",
    "\n",
    "    y      = train_df[\"y\"].to_numpy()\n",
    "    y_pos  = (train_df[\"y\"] > 0).astype(int).to_numpy()\n",
    "    pos_gl = float(y_pos.mean()) if default_posp is None else float(default_posp)\n",
    "    # 保证不是 0 或 1 的极端概率（避免完全屏蔽）\n",
    "    pos_gl = min(max(pos_gl, 0.01), 0.99)\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    pred_test_reg  = np.zeros((len(X_te), n_splits))\n",
    "    pred_test_posp = np.zeros((len(X_te), n_splits))\n",
    "\n",
    "    for k, (tr_idx, va_idx) in enumerate(tscv.split(X, y)):\n",
    "        X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
    "        y_tr, y_va = y[tr_idx], y[va_idx]\n",
    "        p_tr, p_va = y_pos[tr_idx], y_pos[va_idx]\n",
    "\n",
    "        # ========== 分类器：若目标单一，跳过训练 ==========\n",
    "        if np.unique(p_tr).size < 2:\n",
    "            # 使用全局阳性率作为该折预测\n",
    "            pred_test_posp[:, k] = pos_gl\n",
    "        else:\n",
    "            clf = CatBoostClassifier(\n",
    "                depth=6, learning_rate=0.04, iterations=4000,\n",
    "                loss_function=\"Logloss\", eval_metric=\"AUC\",\n",
    "                l2_leaf_reg=3.0, random_seed=seed, verbose=False\n",
    "            )\n",
    "            clf.fit(Pool(X_tr, p_tr, cat_features=CAT_COLS),\n",
    "                    eval_set=Pool(X_va, p_va, cat_features=CAT_COLS),\n",
    "                    verbose=False)\n",
    "            pred_test_posp[:, k] = clf.predict_proba(X_te)[:, 1]\n",
    "\n",
    "        # ========== 回归器：若无正样本，跳过训练 ==========\n",
    "        mask_tr = y_tr > 0\n",
    "        if mask_tr.sum() == 0:\n",
    "            if default_reg_pred is not None:\n",
    "                pred_test_reg[:, k] = np.asarray(default_reg_pred, float)\n",
    "            else:\n",
    "                # 退化为全局均值\n",
    "                pred_test_reg[:, k] = max(float(y.mean()), 0.0)\n",
    "        else:\n",
    "            reg = CatBoostRegressor(\n",
    "                depth=8, learning_rate=0.03, iterations=6000,\n",
    "                loss_function=\"MAE\", eval_metric=\"MAE\",\n",
    "                l2_leaf_reg=2.0, random_seed=seed + k, verbose=False\n",
    "            )\n",
    "            reg.fit(Pool(X_tr[mask_tr], np.log1p(y_tr[mask_tr]), cat_features=CAT_COLS),\n",
    "                    eval_set=Pool(X_va, np.log1p(np.maximum(y_va, 0)), cat_features=CAT_COLS),\n",
    "                    verbose=False)\n",
    "            pred_test_reg[:, k] = np.expm1(np.maximum(reg.predict(X_te), 0.0))\n",
    "\n",
    "    reg_te  = pred_test_reg.mean(axis=1)\n",
    "    posp_te = pred_test_posp.mean(axis=1)\n",
    "    return reg_te, posp_te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7ddb8ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:49.021459Z",
     "iopub.status.busy": "2025-10-10T04:04:49.020591Z",
     "iopub.status.idle": "2025-10-10T04:04:49.142265Z",
     "shell.execute_reply": "2025-10-10T04:04:49.140431Z"
    },
    "papermill": {
     "duration": 0.132676,
     "end_time": "2025-10-10T04:04:49.144423",
     "exception": false,
     "start_time": "2025-10-10T04:04:49.011747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ================= 数据清理 & 去重（若你之前已做，这几行再次执行也安全） =================\n",
    "for df in (train_df, test_df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "train_df = train_df[train_df[\"y\"].notna()].copy()\n",
    "train_df[\"y\"] = pd.to_numeric(train_df[\"y\"], errors=\"coerce\").clip(lower=0)\n",
    "train_df = dedupe_panel(train_df)\n",
    "test_df  = dedupe_panel(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6a3c69d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:49.162187Z",
     "iopub.status.busy": "2025-10-10T04:04:49.161905Z",
     "iopub.status.idle": "2025-10-10T04:04:49.166895Z",
     "shell.execute_reply": "2025-10-10T04:04:49.165564Z"
    },
    "papermill": {
     "duration": 0.015471,
     "end_time": "2025-10-10T04:04:49.168699",
     "exception": false,
     "start_time": "2025-10-10T04:04:49.153228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ================= 季节基线（若未计算则计算） =================\n",
    "if \"hw_te\" not in globals() or \"ew_te\" not in globals():\n",
    "    hw_te, ew_te = build_baselines(base, test_df, TARGET_COL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dfc30894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:04:49.188190Z",
     "iopub.status.busy": "2025-10-10T04:04:49.187902Z",
     "iopub.status.idle": "2025-10-10T04:18:12.828560Z",
     "shell.execute_reply": "2025-10-10T04:18:12.827272Z"
    },
    "papermill": {
     "duration": 803.659273,
     "end_time": "2025-10-10T04:18:12.837075",
     "exception": false,
     "start_time": "2025-10-10T04:04:49.177802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2380699826.py:22: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in train_df and not pd.api.types.is_categorical_dtype(train_df[c]):\n",
      "/tmp/ipykernel_13/2380699826.py:24: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if c in test_df and not pd.api.types.is_categorical_dtype(test_df[c]):\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n",
      "No objects info loaded\n"
     ]
    }
   ],
   "source": [
    "# 若缺失则训练\n",
    "if \"reg_te\" not in globals() or \"posp_te\" not in globals():\n",
    "    # default_reg_pred 用季节性基线 ew_te；default_posp 用全局阳性率（可不传）\n",
    "    reg_te, posp_te = train_two_stage_and_predict(\n",
    "        train_df, test_df,\n",
    "        FEATURES=None, CAT_COLS=None,\n",
    "        n_splits=4, seed=42,\n",
    "        default_reg_pred=ew_te\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f10b1f89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:18:12.854139Z",
     "iopub.status.busy": "2025-10-10T04:18:12.853762Z",
     "iopub.status.idle": "2025-10-10T04:18:12.873133Z",
     "shell.execute_reply": "2025-10-10T04:18:12.871949Z"
    },
    "papermill": {
     "duration": 0.029755,
     "end_time": "2025-10-10T04:18:12.874495",
     "exception": false,
     "start_time": "2025-10-10T04:18:12.844740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "thr    = 0.65\n",
    "z_gate = (posp_te >= thr).astype(int)\n",
    "\n",
    "shrink = 0.35\n",
    "pred_te = shrink * reg_te + (1 - shrink) * ew_te\n",
    "\n",
    "caps = (train_df.groupby(\"sector_id\")[\"y\"]\n",
    "        .quantile([0.01, 0.99]).unstack()\n",
    "        .rename(columns={0.01:\"lo\", 0.99:\"hi\"})\n",
    "        .reset_index())\n",
    "caps = test_df[[\"sector_id\"]].merge(caps, on=\"sector_id\", how=\"left\").fillna(0.0)\n",
    "hi_cap = np.maximum(caps[\"hi\"].values * 1.25, 1.0)\n",
    "pred_te = np.minimum(np.maximum(pred_te, 0.0), hi_cap)\n",
    "\n",
    "final_pred = pred_te * z_gate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2bf92cc1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T04:18:12.892758Z",
     "iopub.status.busy": "2025-10-10T04:18:12.891741Z",
     "iopub.status.idle": "2025-10-10T04:18:12.921183Z",
     "shell.execute_reply": "2025-10-10T04:18:12.920391Z"
    },
    "papermill": {
     "duration": 0.039812,
     "end_time": "2025-10-10T04:18:12.922680",
     "exception": false,
     "start_time": "2025-10-10T04:18:12.882868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /kaggle/working/submission.csv\n",
      "                id  new_house_transaction_amount\n",
      " 2024 Aug_sector 1                      0.000000\n",
      " 2024 Aug_sector 2                      0.000000\n",
      " 2024 Aug_sector 3                      0.000000\n",
      " 2024 Aug_sector 4                      0.000000\n",
      " 2024 Aug_sector 5                      0.000000\n",
      " 2024 Aug_sector 6                      0.000000\n",
      " 2024 Aug_sector 7                      0.000000\n",
      " 2024 Aug_sector 8                      0.000000\n",
      " 2024 Aug_sector 9                      0.000000\n",
      "2024 Aug_sector 10                      0.000000\n"
     ]
    }
   ],
   "source": [
    "# 生成提交（按键合并）\n",
    "test2 = split_test_id(test.copy())\n",
    "pred_df = test_df[[\"time\",\"sector_id\"]].copy()\n",
    "pred_df[\"pred\"] = final_pred\n",
    "pred_df = pred_df.groupby([\"time\",\"sector_id\"], as_index=False)[\"pred\"].mean()\n",
    "\n",
    "submit = test2.merge(pred_df, on=[\"time\",\"sector_id\"], how=\"left\")\n",
    "submit[\"new_house_transaction_amount\"] = submit[\"pred\"].fillna(0.0).astype(float)\n",
    "submit = submit[[\"id\", \"new_house_transaction_amount\"]]\n",
    "submit.to_csv(OUT/\"submission.csv\", index=False)\n",
    "print(\"Saved:\", OUT/\"submission.csv\")\n",
    "print(submit.head(10).to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13320609,
     "sourceId": 111876,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 826.586921,
   "end_time": "2025-10-10T04:18:13.754903",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-10T04:04:27.167982",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
